{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2736326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\torch\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\user\\.conda\\envs\\torch\\lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465d3ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"device = {device}\")\n",
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb3b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784 # 28 * 28\n",
    "num_epochs = 300\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66cdb635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_51036/1117618835.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmnist_train\u001b[0m \u001b[1;31m# 6a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist_train' is not defined"
     ]
    }
   ],
   "source": [
    "mnist_train # 6a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82b7f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Processing\n",
    "transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.5], # 1 for gray scale 만약, RGB channels라면 mean=(0.5, 0.5, 0.5)\n",
    "                                         std=[0.5])])  # 1 for gray scale 만약, RGB channels라면 std=(0.5, 0.5, 0.5)\n",
    "\n",
    "# MNIST 데이터셋\n",
    "mnist_train = dsets.MNIST(root='data/',\n",
    "                         train=True, # 트레인 셋\n",
    "                         transform=transform,\n",
    "                         download=True)\n",
    "mnist_test  = dsets.MNIST(root='data/', \n",
    "                          train=False,\n",
    "                          transform=transform,\n",
    "                          download=True)\n",
    "# 랜덤으로 9개만 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "596c6924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(mnist_train), size=(1,)).item()\n",
    "    img, label = mnist_train[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.axis(\"off\") # x축, y축 안보이게 설정\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e3df24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train[0][0].squeeze().min())\n",
    "print(mnist_train[0][0].squeeze().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee709977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train, # 훈련용 데이터 로딩\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True) # 에폭마다 데이터 섞기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0ea9616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "# D = nn.Sequential(\n",
    "#     nn.Linear(image_size, hidden_size),\n",
    "#     nn.LeakyReLU(0.2),\n",
    "#     nn.Linear(hidden_size, hidden_size),\n",
    "#     nn.LeakyReLU(0.2),\n",
    "#     nn.Linear(hidden_size, 1),\n",
    "#     nn.Sigmoid()) # Binary Cross Entropy loss 를 사용할 것이기에 sigmoid 사용!\n",
    "\n",
    "# Generator \n",
    "G1 = nn.Sequential(\n",
    "    nn.Flatten(1), # \n",
    "    nn.Linear(784, 128), # 100*128\n",
    "    nn.BatchNorm1d(128), # 100*128\n",
    "    nn.LeakyReLU(0.2)) # 100*128\n",
    "\n",
    "eta = torch.randn(batch_size, 100, device=device)\n",
    "\n",
    "# G1_out = torch.concat((G1,eta),1).resize(batch_size,228,1,1) # 100*228*1*1\n",
    "\n",
    "G2 = nn.Sequential( # input : G1_out\n",
    "    nn.ConvTranspose2d(228,256,kernel_size=(7,7),stride=(1,1),padding=0), # [100, 256, 7, 7]\n",
    "    nn.BatchNorm2d(256), # \n",
    "    nn.LeakyReLU(0.2), # [100, 256, 7, 7]\n",
    "    nn.ConvTranspose2d(256,128,kernel_size=(5,5),stride=(2,2),padding=2,output_padding =1), # [100, 128, 14, 14]\n",
    "    nn.BatchNorm2d(128), # \n",
    "    nn.LeakyReLU(0.2),#\n",
    "    nn.ConvTranspose2d(128,1,kernel_size=(5,5),stride=(1,1),padding=2), # [100, 1, 14, 14] -> should be matched with size of y.\n",
    "    nn.ReLU()# [100, 1, 14, 14]\n",
    "    )\n",
    "\n",
    "# Device setting\n",
    "# D = D.to(device)\n",
    "G1 = G1.to(device)\n",
    "G2 = G2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "4d599793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0cf64429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 128])\n",
      "torch.Size([100, 228, 1, 1])\n",
      "torch.Size([100, 1, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "for batch_image,batch_label in data_loader:\n",
    "    print(batch_image.size())\n",
    "    print(batch_label.size())\n",
    "    out1 = G1(batch_image.to(device))\n",
    "    print(out1.size())\n",
    "    G1_out = torch.concat((out1,eta),1).resize(batch_size,228,1,1)\n",
    "    print(G1_out.size())\n",
    "    print(G2(G1_out).size())\n",
    "    \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96a886b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = (img+1) / 2\n",
    "    img = img.squeeze() # 차원 중 사이즈 1 을 제거\n",
    "    np_img = img.numpy() # 이미지 픽셀을 넘파이 배열로 변환\n",
    "    plt.imshow(np_img,cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def imshow_grid(img): \n",
    "    img = utils.make_grid(img.cpu().detach()) # 이미지 그리드 생성, 이미지 출력만을 위해 cpu에 담고 추적 방이\n",
    "    img = (img+1)/2\n",
    "    npimg = img.numpy() # 이미지 픽셀을 넘파이 배열로 변환\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a2ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1efd26ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 28, 28])\n",
      "torch.Size([2, 784])\n"
     ]
    }
   ],
   "source": [
    "samp = torch.randn(2,28,28,device=device)\n",
    "print(samp.shape)\n",
    "fn = nn.Flatten(1)\n",
    "res = fn(samp)\n",
    "print(res.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3b086e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128])\n"
     ]
    }
   ],
   "source": [
    "print(G1(samp).size())\n",
    "eta = torch.randn(2, 100, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "af0bfe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 228])\n"
     ]
    }
   ],
   "source": [
    "res2 = torch.concat((G1(samp),eta),1)\n",
    "print(res2.size())\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "beb07cf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38312/1516196942.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got int"
     ]
    }
   ],
   "source": [
    "# 다시 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32da730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자 이용해 데이터 만들기\n",
    "rand = torch.randn(1, 100, device=device)\n",
    "img_1 = G(rand).view(-1,28,28)\n",
    "\n",
    "imshow(img_1.squeeze().cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4776bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch SIze만큼 노이즈 생성하여 그리드로 출력\n",
    "rand = torch.randn(batch_size, 100, device=device)\n",
    "img_1 = G(rand)\n",
    "imshow_grid(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c7f179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary cross entropy loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c70bb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "def reset_grad(): # 가중치를 0으로 초기화\n",
    "    d_optimizer.zero_grad()\n",
    "    g_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_epoch = []\n",
    "dgx_epoch = []\n",
    "total_step = len(data_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        images = images.reshape(batch_size, -1).to(device)\n",
    "        \n",
    "        # Create the labels which are later used as input for the BCE loss\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # ================================================================== #\n",
    "        #                      Train the discriminator                       #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
    "        # Second term of the loss is always zero since real_labels == 1\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        # Compute BCELoss using fake images\n",
    "        # First term of the loss is always zero since fake_labels == 0\n",
    "        z = torch.randn(batch_size, latent_size).to(device)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        reset_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # ================================================================== #\n",
    "        #                        Train the generator                         #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # Compute loss with fake images\n",
    "        z = torch.randn(batch_size, latent_size).to(device)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "    \n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        reset_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        if (i+1) % 200 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n",
    "                          real_score.mean().item(), fake_score.mean().item()))\n",
    "    dx_epoch.append(real_score.mean().item())            \n",
    "    dgx_epoch.append(fake_score.mean().item())\n",
    "    # real image 저장\n",
    "    if (epoch+1) == 1:\n",
    "        images = images.reshape(images.size(0), 1, 28, 28)\n",
    "        save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))\n",
    "    \n",
    "    # 생성된 이미지 저장\n",
    "    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n",
    "\n",
    "# 생성자, 판별자 각각 모델 저장\n",
    "torch.save(G.state_dict(), 'G.ckpt')\n",
    "torch.save(D.state_dict(), 'D.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cb8802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot    \n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('score')\n",
    "x = np.arange(num_epochs)\n",
    "plt.plot(x, dx_epoch, 'g', label='D(x)')\n",
    "plt.plot(x, dgx_epoch, 'b', label='D(G(z))')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14273101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0117e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe0789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbb6307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e689af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959e5b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
